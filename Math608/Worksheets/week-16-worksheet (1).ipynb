{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATH 608 Week 16 Worksheet\n",
    "## Penguins Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "      <th>is_biscoe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "5  Adelie  Torgersen            39.3           20.6              190.0   \n",
       "\n",
       "   body_mass_g     sex  year  is_biscoe  \n",
       "0       3750.0    male  2007          0  \n",
       "1       3800.0  female  2007          0  \n",
       "2       3250.0  female  2007          0  \n",
       "4       3450.0  female  2007          0  \n",
       "5       3650.0    male  2007          0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/roualdes/data/refs/heads/master/penguins.csv\"\n",
    "penguins = pd.read_csv(url)\n",
    "penguins = penguins.dropna()\n",
    "\n",
    "# Create binary target for Biscoe island\n",
    "penguins['is_biscoe'] = (penguins['island'] == 'Biscoe').astype(int)\n",
    "\n",
    "# Prepare the features and target\n",
    "X = penguins[['bill_depth_mm']]\n",
    "y = penguins['is_biscoe']\n",
    "y=np.reshape(y,-1)\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=608)\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of being from Biscoe island for bill depth of 17.1 mm: 0.5052002966072995\n",
      "Predicted class: Biscoe\n",
      "Probability of being from Biscoe island for bill depth of 18.1 mm: 0.27457712279904906\n",
      "Predicted class: Not Biscoe\n",
      "Confusion Matrix:\n",
      "[[24  8]\n",
      " [10 25]]\n",
      "Accuracy: 0.7313432835820896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aditya/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/aditya/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/aditya/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/aditya/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fit logistic regression model\n",
    "lr_model = LogisticRegression(random_state=608)\n",
    "#y_train=np.reshape(y_train,-1)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probability for bill depth of 17.1 mm\n",
    "new_penguin = np.array([[17.1]])\n",
    "prob_biscoe = lr_model.predict_proba(new_penguin)[0][1]\n",
    "print(f\"Probability of being from Biscoe island for bill depth of 17.1 mm: {prob_biscoe}\")\n",
    "prediction = lr_model.predict(new_penguin)[0]\n",
    "print(f\"Predicted class: {'Biscoe' if prediction == 1 else 'Not Biscoe'}\")\n",
    "\n",
    "new_penguin = np.array([[18.1]])\n",
    "prob_biscoe = lr_model.predict_proba(new_penguin)[0][1]\n",
    "print(f\"Probability of being from Biscoe island for bill depth of 18.1 mm: {prob_biscoe}\")\n",
    "# Predict class\n",
    "prediction = lr_model.predict(new_penguin)[0]\n",
    "print(f\"Predicted class: {'Biscoe' if prediction == 1 else 'Not Biscoe'}\")\n",
    "\n",
    "# Confusion matrix and accuracy\n",
    "y_pred = lr_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Penalized Logistic Regression\n",
    "\n",
    "### Prepare features with interaction term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of being from Biscoe island bill depth of 17.1 mm and bill length of 45 mm: 0.5099\n",
      "Predicted class: Biscoe\n",
      "Confusion Matrix:\n",
      "[[25  7]\n",
      " [10 25]]\n",
      "Accuracy: 0.7463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aditya/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/aditya/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Prepare features with interaction term\n",
    "X_interaction = penguins[['bill_depth_mm', 'bill_length_mm']].copy()\n",
    "X_interaction['interaction'] = X_interaction['bill_depth_mm'] * X_interaction['bill_length_mm']\n",
    "\n",
    "# Split the data\n",
    "X_train_inter, X_test_inter, y_train, y_test = train_test_split(X_interaction, y, test_size=0.2, random_state=608)\n",
    "\n",
    "# Create pipeline with scaling and logistic regression\n",
    "penalized_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "penalized_model.fit(X_train_inter, y_train)\n",
    "\n",
    "# Predict for specific penguin\n",
    "new_penguin_inter = np.array([[17.1, 45, 17.1 * 45]])\n",
    "prob_biscoe_inter = penalized_model.predict_proba(new_penguin_inter)[0][1]\n",
    "print(f\"Probability of being from Biscoe island bill depth of 17.1 mm and bill length of 45 mm: {prob_biscoe_inter:.4f}\")\n",
    "\n",
    "# Predict class\n",
    "prediction_inter = penalized_model.predict(new_penguin_inter)[0]\n",
    "print(f\"Predicted class: {'Biscoe' if prediction_inter == 1 else 'Not Biscoe'}\")\n",
    "\n",
    "# Confusion matrix and accuracy\n",
    "y_pred_inter = penalized_model.predict(X_test_inter)\n",
    "cm_inter = confusion_matrix(y_test, y_pred_inter)\n",
    "accuracy_inter = accuracy_score(y_test, y_pred_inter)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_inter)\n",
    "print(f\"Accuracy: {accuracy_inter:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the comparison of model accuracies between Simple and Penalized -  Penalized is a better accuracy\n",
    "Penalized is better as it take consider more columns to make perdictions - ['bill_depth_mm', 'bill_length_mm']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploring Alternative Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Features Model:\n",
      "Confusion Matrix:\n",
      "[[30  2]\n",
      " [10 25]]\n",
      "Accuracy: 0.8209\n",
      "\n",
      "Model Comparison:\n",
      "Simple Logistic Regression Accuracy: 0.7313\n",
      "Interaction Term Model Accuracy: 0.7463\n",
      "Polynomial Features Model Accuracy: 0.8209\n"
     ]
    }
   ],
   "source": [
    "# Try polynomial features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Prepare polynomial features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = penguins[['bill_depth_mm', 'bill_length_mm','flipper_length_mm']]\n",
    "X_poly_features = poly.fit_transform(X_poly)\n",
    "\n",
    "# Split the data\n",
    "X_train_poly, X_test_poly, y_train, y_test = train_test_split(X_poly_features, y, test_size=0.2, random_state=608)\n",
    "\n",
    "# Create pipeline with scaling and logistic regression\n",
    "poly_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000, C=1.0)\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "poly_model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_poly = poly_model.predict(X_test_poly)\n",
    "accuracy_poly = accuracy_score(y_test, y_pred_poly)\n",
    "cm_poly = confusion_matrix(y_test, y_pred_poly)\n",
    "\n",
    "print(\"Polynomial Features Model:\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_poly)\n",
    "print(f\"Accuracy: {accuracy_poly:.4f}\")\n",
    "\n",
    "# Print comparison of model accuracies\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(f\"Simple Logistic Regression Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Interaction Term Model Accuracy: {accuracy_inter:.4f}\")\n",
    "print(f\"Polynomial Features Model Accuracy: {accuracy_poly:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
